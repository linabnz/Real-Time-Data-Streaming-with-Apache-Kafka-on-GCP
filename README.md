#  KEFTA GROUP â€“ Real-Time Data Streaming Platform

> **Kefta ou Kafka ?**  
>  Ne pas confondre Kefta et Kafka...  
> Lâ€™un vous alimente en donnÃ©es, lâ€™autre en protÃ©ines grillÃ©es ğŸ¢

---

##  Objectif du projet

CrÃ©er une plateforme de **streaming Big Data** en temps rÃ©el permettant de :
- Suivre la distance entre un taxi et son client
- Estimer le prix dâ€™un trajet en fonction du niveau de confort (low / medium / high)
- Visualiser les donnÃ©es en direct
- Faire de lâ€™analyse et du Machine Learning sur BigQuery

---

##  Stack Technique

| Outil           | RÃ´le |
|------------------|------|
| **Python**       | Producteur de donnÃ©es vers Kafka |
| **Apache Kafka** | Buffer de streaming |
| **Apache NiFi**  | ETL / Transformation / Routage |
| **Elasticsearch**| Indexation pour la recherche |
| **Kibana**       | Visualisation en temps rÃ©el |
| **GCS**          | Stockage externalisÃ© |
| **BigQuery**     | Data Warehouse + ML en SQL |

---

##  Architecture du pipeline

![Architecture](architecture/kefta_architecture.jpg)

---

##  Structure du dÃ©pÃ´t `kefta-group/`

Voici la structure du projet avec une description pour chaque dossier/fichier :

```bash
kefta-group/
â”œâ”€â”€ kafka/                      # Scripts producteurs Python envoyant les donnÃ©es Ã  Kafka
â”‚   â””â”€â”€ producer.py             # Script principal pour produire les donnÃ©es
â”‚
â”œâ”€â”€ nifi/                       # Composants liÃ©s Ã  Apache NiFi
â”‚   â”œâ”€â”€ kefta-template.xml      # Template XML exportÃ© depuis NiFi
â”‚   â””â”€â”€ documentation.md        # Documentation du flow NiFi
â”‚
â”œâ”€â”€ gcs_bigquery/               # Scripts SQL pour Google Cloud Storage et BigQuery ML
â”‚   â”œâ”€â”€ external_table.sql      # CrÃ©ation de la table externe pointant sur GCS
â”‚   â””â”€â”€ kmeans_model.sql        # ModÃ¨le KMeans sur BigQuery (latitude/longitude)
â”‚
â”œâ”€â”€ elasticsearch_kibana/       # Configuration Elasticsearch et dashboards Kibana
â”‚   â”œâ”€â”€ mapping.json            # Mapping personnalisÃ© des champs Elasticsearch
â”‚   â””â”€â”€ dashboard_screenshot.png # Capture du dashboard Kibana
â”‚
â”œâ”€â”€ data/                       # DonnÃ©es d'entrÃ©e (JSON, CSV)
â”‚   â”œâ”€â”€ data_projet.json        # DonnÃ©es simulÃ©es envoyÃ©es dans Kafka
â”‚   â””â”€â”€ uber-split2.csv         # Fichier utilisÃ© pour le clustering BigQuery
â”‚
â”œâ”€â”€ architecture/               # Architecture technique du projet
â”‚   â”œâ”€â”€ kefta_architecture.png  # SchÃ©ma visuel de lâ€™architecture du pipeline
â”‚   â””â”€â”€ budget_estimation.md    # Estimation du coÃ»t sur Google Cloud
â”‚
â”œâ”€â”€ .gitignore                  # Fichier pour ignorer les fichiers inutiles au versionnage
â””â”€â”€ README.md                   # Documentation principale du projet

```
---

##  Workflow dÃ©taillÃ©

1. **Kafka** reÃ§oit les donnÃ©es depuis un script Python
2. **NiFi** transforme et envoie :
   - les donnÃ©es vers **Elasticsearch** pour la visualisation
   - et vers **GCS** au format Parquet
3. **BigQuery** analyse les fichiers Parquet pour :
   - Clustering en KMeans (8 clusters gÃ©ographiques)
   - Calcul du chiffre dâ€™affaires par niveau de confort

---

##  Visualisation

- Dashboard en temps rÃ©el dans **Kibana**
- DonnÃ©es historisÃ©es consultables via **BigQuery SQL**
- Mapping des donnÃ©es dÃ©fini dans `mapping.json`

---

##  Machine Learning sur BigQuery

Clustering des clients/taxis basÃ© sur leurs coordonnÃ©es 